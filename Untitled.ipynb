{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3da9be8-3475-4d33-ad65-7ee5e626be7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "def all_permutations(input_list):\n",
    "    return list(itertools.permutations(input_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2076a93-43b7-4364-bf42-fe7dd595776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hangman_string(input_string, char_list):\n",
    "    intermediate_strings = [input_string]  # Initialize the list with the original input_string\n",
    "\n",
    "    for char in char_list:\n",
    "        input_string = input_string.replace(char, '_')\n",
    "        intermediate_strings.append(input_string)\n",
    "\n",
    "    return intermediate_strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071c6577-bba1-45c4-a172-fbc95b41848a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de600fed-80ae-442e-a396-87139f84c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_generator(string_):\n",
    "    df_super = pd.DataFrame(columns=['X','Y'])\n",
    "    all_unique_char = sorted(list(set(string_)))\n",
    "    char_list = list(all_permutations(all_unique_char))\n",
    "    for char_list_item in char_list:\n",
    "        lst = hangman_string(string_,char_list_item)\n",
    "        # Separate keys and values\n",
    "        keys = lst[1:]  # All elements except the first one\n",
    "        values = lst[:-1]  # All elements except the last one\n",
    "        # print(char_list_item)\n",
    "        # Create the DataFrame\n",
    "        df = pd.DataFrame({'X': keys, 'Y': values})\n",
    "        # print(df)\n",
    "        df_super = pd.concat([df_super, df], axis=0) \n",
    "        # break\n",
    "    return df_super\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "92e2ffc5-6cc5-4f3d-bb7a-56c068dd9fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_ = 'aalesund'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cf1b94db-ee98-4e7e-a914-38281106b9a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# permutation_generator(string_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4ebfe9-e0f5-4bcf-a791-23699b9f98d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f7d1c338-d964-4409-907e-d3ea85830089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7056.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "35280/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3514f9-547c-4d6d-88e5-9163e79fe377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4cd6fb2d-769a-4de7-a70a-7947f5953af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_unique_char = sorted(list(set(string_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "461ab926-0c6d-4012-a663-1a4b715a6878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'd', 'e', 'l', 'n', 's', 'u']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_unique_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f948e7cb-571b-4fa8-b641-2a70e798c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_list = list(all_permutations(all_unique_char))[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5661106b-76a7-4244-8d3a-cc719b53a8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('u', 's', 'n', 'l', 'd', 'e', 'a')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c7242e75-5e51-44b1-b21b-2e38910873fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3628800"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(all_permutations(all_unique_char)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e44fff1d-441f-470c-aa5c-ce99fcfa01c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = hangman_string(string_,char_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82efc997-5c30-4e51-b8ca-51a25314bf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate keys and values\n",
    "keys = lst[1:]  # All elements except the first one\n",
    "values = lst[:-1]  # All elements except the last one\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame({'X': keys, 'Y': values})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "378fd4b3-a8d8-440b-8850-cec2ba70a46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aba_emen_s</td>\n",
       "      <td>abatements</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aba_emen__</td>\n",
       "      <td>aba_emen_s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aba_eme___</td>\n",
       "      <td>aba_emen__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aba_e_e___</td>\n",
       "      <td>aba_eme___</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a_a_e_e___</td>\n",
       "      <td>aba_e_e___</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a_a_______</td>\n",
       "      <td>a_a_e_e___</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>__________</td>\n",
       "      <td>a_a_______</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            X           Y\n",
       "0  aba_emen_s  abatements\n",
       "1  aba_emen__  aba_emen_s\n",
       "2  aba_eme___  aba_emen__\n",
       "3  aba_e_e___  aba_eme___\n",
       "4  a_a_e_e___  aba_e_e___\n",
       "5  a_a_______  a_a_e_e___\n",
       "6  __________  a_a_______"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094c8464-a6c8-436e-9d44-88faa0b4845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0771966-cd07-4d5c-9317-8f9e7fb7c8ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7cd30d-49d5-411c-b49c-8b54a9c496fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108328fd-a8e3-4c07-a2f9-0a7e3bec6a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Step 1: Load the Vocabulary\n",
    "def load_vocabulary(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        words = file.read().splitlines()\n",
    "    return words\n",
    "\n",
    "# Step 2: Tokenization and Preprocessing (assuming you want to use lowercase words)\n",
    "def tokenize_and_preprocess(words):\n",
    "    return [word.lower() for word in words]\n",
    "\n",
    "# Step 3: Build N-Gram Distributions\n",
    "def build_ngram_distribution(words, n):\n",
    "    ngrams = [word[i:i + n] for word in words for i in range(len(word) - n + 1)]\n",
    "    ngram_freq = Counter(ngrams)\n",
    "    total_ngrams = len(ngrams)\n",
    "    ngram_probs = {ngram: count / total_ngrams for ngram, count in ngram_freq.items()}\n",
    "    return ngram_probs\n",
    "\n",
    "# Step 4: Build n-gram distributions for unigrams, bigrams, trigrams, and so on up to 6-grams.\n",
    "def build_all_ngram_distributions(words):\n",
    "    n_grams_distributions = {}\n",
    "    for n in range(1, 7):\n",
    "        n_grams_distributions[n] = build_ngram_distribution(words, n)\n",
    "    return n_grams_distributions\n",
    "\n",
    "# Step 5: Guessing Algorithm\n",
    "def generate_possible_words(incomplete_word):\n",
    "    possible_words = []\n",
    "    for char in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        possible_words.append(incomplete_word.replace('_', char))\n",
    "    return possible_words\n",
    "\n",
    "def calculate_word_probabilities(possible_words, ngram_distribution):\n",
    "    word_probabilities = {}\n",
    "    for word in possible_words:\n",
    "        word_prob = 1.0\n",
    "        for ngram in ngram_distribution:\n",
    "            word_ngram = word[:len(ngram)]\n",
    "            if ngram == word_ngram:\n",
    "                word_prob *= ngram_distribution[ngram]\n",
    "        word_probabilities[word] = word_prob\n",
    "    return word_probabilities\n",
    "\n",
    "def get_best_guess(word_probabilities):\n",
    "    return max(word_probabilities, key=word_probabilities.get)\n",
    "\n",
    "# Example usage:\n",
    "vocabulary_file = './words_250000_train.txt'\n",
    "vocabulary = load_vocabulary(vocabulary_file)\n",
    "tokenized_words = tokenize_and_preprocess(vocabulary)\n",
    "\n",
    "# Build n-gram distributions for unigrams, bigrams, trigrams, and so on up to 6-grams.\n",
    "n_grams_distributions = build_all_ngram_distributions(tokenized_words)\n",
    "\n",
    "# Example: Accessing unigram distribution\n",
    "unigram_distribution = n_grams_distributions[1]\n",
    "\n",
    "# Example: Accessing bigram distribution\n",
    "bigram_distribution = n_grams_distributions[2]\n",
    "\n",
    "# Example: Accessing trigram distribution\n",
    "trigram_distribution = n_grams_distributions[3]\n",
    "\n",
    "# And so on, you can access distributions for 4-grams, 5-grams, and 6-grams.\n",
    "\n",
    "# Example usage of the guessing algorithm:\n",
    "incomplete_word = \"g_ _ _ _d\"\n",
    "possible_words = generate_possible_words(incomplete_word)\n",
    "word_probabilities = calculate_word_probabilities(possible_words, trigram_distribution)\n",
    "best_guess = get_best_guess(word_probabilities)\n",
    "\n",
    "print(\"Possible words:\", possible_words)\n",
    "print(\"Word probabilities:\", word_probabilities)\n",
    "print(\"Best guess:\", best_guess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598a569e-2343-433a-97a4-b9d74b1e5432",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(possible_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0907bb3-c5d4-4ca1-83e7-d7c8843cc9ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
